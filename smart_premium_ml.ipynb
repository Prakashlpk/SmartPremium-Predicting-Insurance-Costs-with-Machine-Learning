{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8c6898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b15bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"D:\\prakash\\Smart_Premium_New\\playground-series-s4e12 (3)\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5c57bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: (1200000, 21)\n",
      "\n",
      "Cleaned dataset size: (1051855, 21)\n",
      "Removed records: 148145\n",
      "\n",
      "Final dataset size: (1051855, 21)\n"
     ]
    }
   ],
   "source": [
    "# Check current dataset size\n",
    "print(f\"Original dataset size: {df_train.shape}\")\n",
    "print()\n",
    "\n",
    "# Calculate premium to income ratio\n",
    "df_train['Premium_to_Income_Ratio'] = (df_train['Premium Amount'] / df_train['Annual Income']) * 100\n",
    "\n",
    "# Remove records where Premium > 50% of Annual Income\n",
    "df_train_cleaned = df_train[df_train['Premium_to_Income_Ratio'] <= 50].copy()\n",
    "\n",
    "# Drop the temporary ratio column\n",
    "df_train_cleaned = df_train_cleaned.drop('Premium_to_Income_Ratio', axis=1)\n",
    "df_train = df_train.drop('Premium_to_Income_Ratio', axis=1)\n",
    "\n",
    "print(f\"Cleaned dataset size: {df_train_cleaned.shape}\")\n",
    "print(f\"Removed records: {len(df_train) - len(df_train_cleaned)}\")\n",
    "print()\n",
    "\n",
    "# Update df_train to cleaned version\n",
    "df_train = df_train_cleaned.copy()\n",
    "\n",
    "print(f\"Final dataset size: {df_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e523f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Missing values handled successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# For numerical columns ‚Üí replace missing values with median\n",
    "num_cols = df_train.select_dtypes(include=['number']).columns\n",
    "df_train[num_cols] = df_train[num_cols].fillna(df_train[num_cols].median())\n",
    "\n",
    "# For categorical columns ‚Üí replace missing values with mode (most frequent value)\n",
    "cat_cols = df_train.select_dtypes(exclude=['number']).columns\n",
    "df_train[cat_cols] = df_train[cat_cols].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "print(\"‚úÖ Missing values handled successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fbe9235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "Age                     0\n",
       "Gender                  0\n",
       "Annual Income           0\n",
       "Marital Status          0\n",
       "Number of Dependents    0\n",
       "Education Level         0\n",
       "Occupation              0\n",
       "Health Score            0\n",
       "Location                0\n",
       "Policy Type             0\n",
       "Previous Claims         0\n",
       "Vehicle Age             0\n",
       "Credit Score            0\n",
       "Insurance Duration      0\n",
       "Policy Start Date       0\n",
       "Customer Feedback       0\n",
       "Smoking Status          0\n",
       "Exercise Frequency      0\n",
       "Property Type           0\n",
       "Premium Amount          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85c3ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ID column copied successfully!\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Take a copy of 'id' column before dropping it\n",
    "id_copy = df_train['id'].copy()\n",
    "\n",
    "print(\"‚úÖ ID column copied successfully!\")\n",
    "print(id_copy.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c08c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f589a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Policy Start Date'] = pd.to_datetime(df_train['Policy Start Date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d26b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Policy_Year'] = df_train['Policy Start Date'].dt.year\n",
    "df_train['Policy_Month'] = df_train['Policy Start Date'].dt.month\n",
    "df_train['Policy_Day'] = df_train['Policy Start Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38cef32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['Policy Start Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a002332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All categorical columns encoded successfully!\n",
      "Encoded columns: ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', 'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Property Type']\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Identify categorical columns\n",
    "# cat_cols = df_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# # Initialize label encoder\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# # Apply label encoding to each categorical column\n",
    "# for col in cat_cols:\n",
    "#     df_train[col] = le.fit_transform(df_train[col])\n",
    "\n",
    "# print(\"‚úÖ All categorical columns encoded successfully!\")\n",
    "# print(\"Encoded columns:\", list(cat_cols))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa25a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All categorical columns encoded successfully!\n",
      "Encoded columns: ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', 'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Property Type']\n",
      "üíæ Saved all label encoders to label_encoders.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = df_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Dictionary to store encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Apply label encoding to each categorical column\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col])\n",
    "    label_encoders[col] = le   # store encoder for that column\n",
    "\n",
    "print(\"‚úÖ All categorical columns encoded successfully!\")\n",
    "print(\"Encoded columns:\", list(cat_cols))\n",
    "\n",
    "# Save all encoders in one .pkl file\n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "print(\"üíæ Saved all label encoders to label_encoders.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b8afbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 0 outliers\n",
      "Gender: 0 outliers\n",
      "Annual Income: 70612 outliers\n",
      "Marital Status: 0 outliers\n",
      "Number of Dependents: 0 outliers\n",
      "Education Level: 0 outliers\n",
      "Occupation: 0 outliers\n",
      "Health Score: 0 outliers\n",
      "Location: 0 outliers\n",
      "Policy Type: 0 outliers\n",
      "Previous Claims: 52509 outliers\n",
      "Vehicle Age: 0 outliers\n",
      "Credit Score: 0 outliers\n",
      "Insurance Duration: 0 outliers\n",
      "Customer Feedback: 0 outliers\n",
      "Smoking Status: 0 outliers\n",
      "Exercise Frequency: 0 outliers\n",
      "Property Type: 0 outliers\n",
      "Premium Amount: 48924 outliers\n",
      "Policy_Year: 0 outliers\n",
      "Policy_Month: 0 outliers\n",
      "Policy_Day: 0 outliers\n"
     ]
    }
   ],
   "source": [
    "# Select only numeric columns\n",
    "num_cols = df_train.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Loop through each numeric column\n",
    "for col in num_cols:\n",
    "    Q1 = df_train[col].quantile(0.25)\n",
    "    Q3 = df_train[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df_train[(df_train[col] < lower_bound) | (df_train[col] > upper_bound)]\n",
    "\n",
    "    print(f\"{col}: {len(outliers)} outliers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08f05277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Log transformation applied to outlier columns successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List of columns with outliers\n",
    "cols_with_outliers = ['Annual Income', 'Previous Claims']\n",
    "\n",
    "# Apply log(1 + x) transform to handle zeros safely\n",
    "for col in cols_with_outliers:\n",
    "    df_train[col] = np.log1p(df_train[col])\n",
    "\n",
    "print(\"‚úÖ Log transformation applied to outlier columns successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8a11bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df_train.drop(columns=['Premium Amount'])\n",
    "y = df_train['Premium Amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      \n",
    "    random_state=42     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "302ad982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db0feaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scaler saved successfully as 'scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the fitted scaler to a file\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"‚úÖ Scaler saved successfully as 'scaler.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e3b5aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Linear Regression Model Results:\n",
      "Root Mean Squared Error (RMSE): 809.5278\n",
      "Mean Absolute Error (MAE): 616.4562\n",
      "R¬≤ Score: 0.0191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Training the model on scaled training data\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on scaled test data\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "mae = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2 = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"‚úÖ Linear Regression Model Results:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1cdc644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Decision Tree Regression Model Results:\n",
      "Root Mean Squared Error (RMSE): 784.4845\n",
      "Mean Absolute Error (MAE): 581.9518\n",
      "R¬≤ Score: 0.0788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Decision Tree model with hyperparameters to prevent overfitting\n",
    "dt_model = DecisionTreeRegressor(\n",
    "    max_depth=10,            # Limit tree depth\n",
    "    min_samples_split=20,    # Minimum samples required to split a node\n",
    "    min_samples_leaf=10,     # Minimum samples required in a leaf node\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on original (unscaled) training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on original (unscaled) test data\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "mae = mean_absolute_error(y_test, y_pred_dt)\n",
    "r2 = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"‚úÖ Decision Tree Regression Model Results:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a34a5011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Random Forest Regression Model Results:\n",
      "Root Mean Squared Error (RMSE): 782.5511\n",
      "Mean Absolute Error (MAE): 580.9309\n",
      "R¬≤ Score: 0.0834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,        # Number of trees in the forest\n",
    "    max_depth=10,            # Maximum depth of each tree\n",
    "    min_samples_split=20,    # Minimum samples required to split a node\n",
    "    min_samples_leaf=10,     # Minimum samples required in a leaf node\n",
    "    random_state=42,\n",
    "    n_jobs=-1                # Use all CPU cores for faster training\n",
    ")\n",
    "\n",
    "# Train the model on original (unscaled) training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on original (unscaled) test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"‚úÖ Random Forest Regression Model Results:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45522fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ XGBoost Regression Model Results:\n",
      "Root Mean Squared Error (RMSE): 783.6993\n",
      "Mean Absolute Error (MAE): 583.6715\n",
      "R¬≤ Score: 0.0807\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=200,        # Number of boosting rounds (trees)\n",
    "    learning_rate=0.05,      # Step size shrinkage\n",
    "    max_depth=10,            # Maximum depth of each tree\n",
    "    subsample=0.8,           # Randomly sample 80% of data for each tree\n",
    "    colsample_bytree=0.8,    # Use 80% of features per tree\n",
    "    reg_lambda=1.0,          # L2 regularization\n",
    "    random_state=42,\n",
    "    n_jobs=-1,               # Use all CPU cores\n",
    "    verbosity=0              # Suppress training logs\n",
    ")\n",
    "\n",
    "# Train the model on original (unscaled) training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on original (unscaled) test data\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "mae = mean_absolute_error(y_test, y_pred_xgb)\n",
    "r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"‚úÖ XGBoost Regression Model Results:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26a4cc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Random Forest model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# ‚úÖ Save the best Random Forest model\n",
    "joblib.dump(rf_model, \"randomforest_model.pkl\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Random Forest model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c353e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = joblib.load(\"randomforest_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9eb6d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature columns saved as regression_feature_cols.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(X.columns.tolist(), \"regression_feature_cols.pkl\")\n",
    "print(\"‚úÖ Feature columns saved as regression_feature_cols.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5baca2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = joblib.load(\"randomforest_model.pkl\")\n",
    "feature_cols = joblib.load(\"regression_feature_cols.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ee0ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_train.reindex(columns=feature_cols, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0578f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "625ab69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ submission.csv created successfully!\n",
      "   id  Premium Amount\n",
      "0   0     1216.513681\n",
      "1   1     1052.359743\n",
      "2   2     1107.406885\n",
      "3   3     1107.096844\n",
      "4   4     1065.489001\n",
      "5   5     1103.737773\n",
      "6   6     1102.322442\n",
      "7   7     1111.169333\n",
      "8   8      316.155418\n",
      "9   9      256.029272\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": id_copy,\n",
    "    \"Premium Amount\": np.round(predictions, 6)\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"üìÅ submission.csv created successfully!\")\n",
    "print(submission.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc6c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
