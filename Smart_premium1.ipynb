{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c6a8f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994cfb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"D:\\prakash\\Smart_Premium_New\\playground-series-s4e12 (3)\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f28b362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: (1200000, 21)\n",
      "\n",
      "Cleaned dataset size: (1051855, 21)\n",
      "Removed records: 148145\n",
      "\n",
      "Final dataset size: (1051855, 21)\n"
     ]
    }
   ],
   "source": [
    "# Check current dataset size\n",
    "print(f\"Original dataset size: {df_train.shape}\")\n",
    "print()\n",
    "\n",
    "# Calculate premium to income ratio\n",
    "df_train['Premium_to_Income_Ratio'] = (df_train['Premium Amount'] / df_train['Annual Income']) * 100\n",
    "\n",
    "# Remove records where Premium > 50% of Annual Income\n",
    "df_train_cleaned = df_train[df_train['Premium_to_Income_Ratio'] <= 50].copy()\n",
    "\n",
    "# Drop the temporary ratio column\n",
    "df_train_cleaned = df_train_cleaned.drop('Premium_to_Income_Ratio', axis=1)\n",
    "df_train = df_train.drop('Premium_to_Income_Ratio', axis=1)\n",
    "\n",
    "print(f\"Cleaned dataset size: {df_train_cleaned.shape}\")\n",
    "print(f\"Removed records: {len(df_train) - len(df_train_cleaned)}\")\n",
    "print()\n",
    "\n",
    "# Update df_train to cleaned version\n",
    "df_train = df_train_cleaned.copy()\n",
    "\n",
    "print(f\"Final dataset size: {df_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4fbc588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before:\n",
      "id                           0\n",
      "Age                      16404\n",
      "Gender                       0\n",
      "Annual Income                0\n",
      "Marital Status           15822\n",
      "Number of Dependents     96384\n",
      "Education Level              0\n",
      "Occupation              315017\n",
      "Health Score             59415\n",
      "Location                     0\n",
      "Policy Type                  0\n",
      "Previous Claims         322859\n",
      "Vehicle Age                  4\n",
      "Credit Score            122455\n",
      "Insurance Duration           1\n",
      "Policy Start Date            0\n",
      "Customer Feedback        65992\n",
      "Smoking Status               0\n",
      "Exercise Frequency           0\n",
      "Property Type                0\n",
      "Premium Amount               0\n",
      "dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_3188\\889289574.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_3188\\889289574.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_3188\\889289574.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_3188\\889289574.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_3188\\889289574.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_3188\\889289574.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_3188\\889289574.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_3188\\889289574.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_3188\\889289574.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after:\n",
      "id                      0\n",
      "Age                     0\n",
      "Gender                  0\n",
      "Annual Income           0\n",
      "Marital Status          0\n",
      "Number of Dependents    0\n",
      "Education Level         0\n",
      "Occupation              0\n",
      "Health Score            0\n",
      "Location                0\n",
      "Policy Type             0\n",
      "Previous Claims         0\n",
      "Vehicle Age             0\n",
      "Credit Score            0\n",
      "Insurance Duration      0\n",
      "Policy Start Date       0\n",
      "Customer Feedback       0\n",
      "Smoking Status          0\n",
      "Exercise Frequency      0\n",
      "Property Type           0\n",
      "Premium Amount          0\n",
      "dtype: int64\n",
      "\n",
      "All missing values handled!\n"
     ]
    }
   ],
   "source": [
    "# Check missing values before\n",
    "print(\"Missing values before:\")\n",
    "print(df_train.isnull().sum())\n",
    "print()\n",
    "\n",
    "# Numerical columns - fill with median\n",
    "numerical_cols = ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', \n",
    "                  'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "\n",
    "for col in numerical_cols:\n",
    "    df_train[col].fillna(df_train[col].median(), inplace=True)\n",
    "\n",
    "# Categorical columns - fill with mode (most frequent value)\n",
    "categorical_cols = ['Marital Status', 'Occupation', 'Customer Feedback']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df_train[col].fillna(df_train[col].mode()[0], inplace=True)\n",
    "\n",
    "# Check missing values after\n",
    "print(\"Missing values after:\")\n",
    "print(df_train.isnull().sum())\n",
    "print()\n",
    "\n",
    "print(\"All missing values handled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1bfd18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping id:\n",
      "['Age', 'Gender', 'Annual Income', 'Marital Status', 'Number of Dependents', 'Education Level', 'Occupation', 'Health Score', 'Location', 'Policy Type', 'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration', 'Policy Start Date', 'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Property Type', 'Premium Amount']\n",
      "\n",
      "Data types:\n",
      "Age                            float64\n",
      "Gender                          object\n",
      "Annual Income                  float64\n",
      "Marital Status                  object\n",
      "Number of Dependents           float64\n",
      "Education Level                 object\n",
      "Occupation                      object\n",
      "Health Score                   float64\n",
      "Location                        object\n",
      "Policy Type                     object\n",
      "Previous Claims                float64\n",
      "Vehicle Age                    float64\n",
      "Credit Score                   float64\n",
      "Insurance Duration             float64\n",
      "Policy Start Date       datetime64[ns]\n",
      "Customer Feedback               object\n",
      "Smoking Status                  object\n",
      "Exercise Frequency              object\n",
      "Property Type                   object\n",
      "Premium Amount                 float64\n",
      "dtype: object\n",
      "\n",
      "Final shape: (1051855, 20)\n"
     ]
    }
   ],
   "source": [
    "# Delete id column\n",
    "df_train = df_train.drop('id', axis=1)\n",
    "\n",
    "# Convert Policy Start Date to datetime\n",
    "df_train['Policy Start Date'] = pd.to_datetime(df_train['Policy Start Date'])\n",
    "\n",
    "# Check the changes\n",
    "print(\"Columns after dropping id:\")\n",
    "print(df_train.columns.tolist())\n",
    "print()\n",
    "\n",
    "print(\"Data types:\")\n",
    "print(df_train.dtypes)\n",
    "print()\n",
    "\n",
    "print(f\"Final shape: {df_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d966a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1051855 entries, 0 to 1199997\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count    Dtype         \n",
      "---  ------                --------------    -----         \n",
      " 0   Age                   1051855 non-null  float64       \n",
      " 1   Gender                1051855 non-null  object        \n",
      " 2   Annual Income         1051855 non-null  float64       \n",
      " 3   Marital Status        1051855 non-null  object        \n",
      " 4   Number of Dependents  1051855 non-null  float64       \n",
      " 5   Education Level       1051855 non-null  object        \n",
      " 6   Occupation            1051855 non-null  object        \n",
      " 7   Health Score          1051855 non-null  float64       \n",
      " 8   Location              1051855 non-null  object        \n",
      " 9   Policy Type           1051855 non-null  object        \n",
      " 10  Previous Claims       1051855 non-null  float64       \n",
      " 11  Vehicle Age           1051855 non-null  float64       \n",
      " 12  Credit Score          1051855 non-null  float64       \n",
      " 13  Insurance Duration    1051855 non-null  float64       \n",
      " 14  Policy Start Date     1051855 non-null  datetime64[ns]\n",
      " 15  Customer Feedback     1051855 non-null  object        \n",
      " 16  Smoking Status        1051855 non-null  object        \n",
      " 17  Exercise Frequency    1051855 non-null  object        \n",
      " 18  Property Type         1051855 non-null  object        \n",
      " 19  Premium Amount        1051855 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(9), object(10)\n",
      "memory usage: 168.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a322a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                     0\n",
       "Gender                  0\n",
       "Annual Income           0\n",
       "Marital Status          0\n",
       "Number of Dependents    0\n",
       "Education Level         0\n",
       "Occupation              0\n",
       "Health Score            0\n",
       "Location                0\n",
       "Policy Type             0\n",
       "Previous Claims         0\n",
       "Vehicle Age             0\n",
       "Credit Score            0\n",
       "Insurance Duration      0\n",
       "Policy Start Date       0\n",
       "Customer Feedback       0\n",
       "Smoking Status          0\n",
       "Exercise Frequency      0\n",
       "Property Type           0\n",
       "Premium Amount          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7666f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('cleaned_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef1f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(r\"D:\\prakash\\Smart_Premium_New\\playground-series-s4e12 (3)\\cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d47d0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1051855 entries, 0 to 1051854\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count    Dtype  \n",
      "---  ------                --------------    -----  \n",
      " 0   Age                   1051855 non-null  float64\n",
      " 1   Gender                1051855 non-null  object \n",
      " 2   Annual Income         1051855 non-null  float64\n",
      " 3   Marital Status        1051855 non-null  object \n",
      " 4   Number of Dependents  1051855 non-null  float64\n",
      " 5   Education Level       1051855 non-null  object \n",
      " 6   Occupation            1051855 non-null  object \n",
      " 7   Health Score          1051855 non-null  float64\n",
      " 8   Location              1051855 non-null  object \n",
      " 9   Policy Type           1051855 non-null  object \n",
      " 10  Previous Claims       1051855 non-null  float64\n",
      " 11  Vehicle Age           1051855 non-null  float64\n",
      " 12  Credit Score          1051855 non-null  float64\n",
      " 13  Insurance Duration    1051855 non-null  float64\n",
      " 14  Policy Start Date     1051855 non-null  object \n",
      " 15  Customer Feedback     1051855 non-null  object \n",
      " 16  Smoking Status        1051855 non-null  object \n",
      " 17  Exercise Frequency    1051855 non-null  object \n",
      " 18  Property Type         1051855 non-null  object \n",
      " 19  Premium Amount        1051855 non-null  float64\n",
      "dtypes: float64(9), object(11)\n",
      "memory usage: 160.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caae69e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: FEATURE ENGINEERING\n",
      "============================================================\n",
      "Features after engineering: 40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STEP 1: FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract datetime features from Policy Start Date\n",
    "df_train['Policy Start Date'] = pd.to_datetime(df_train['Policy Start Date'])\n",
    "df_train['Policy_Year'] = df_train['Policy Start Date'].dt.year\n",
    "df_train['Policy_Month'] = df_train['Policy Start Date'].dt.month\n",
    "df_train['Policy_Day'] = df_train['Policy Start Date'].dt.day\n",
    "df_train = df_train.drop('Policy Start Date', axis=1)\n",
    "\n",
    "# Create binned features\n",
    "df_train['Age_Group'] = pd.cut(df_train['Age'], bins=[0, 25, 35, 45, 55, 100], \n",
    "                                labels=['18-25', '26-35', '36-45', '46-55', '55+'])\n",
    "df_train['Income_Group'] = pd.cut(df_train['Annual Income'], bins=[0, 30000, 60000, 100000, 200000], \n",
    "                                   labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "df_train['Vehicle_Category'] = pd.cut(df_train['Vehicle Age'], bins=[-1, 3, 7, 15, 20], \n",
    "                                       labels=['New', 'Mid', 'Old', 'Very Old'])\n",
    "df_train['Credit_Category'] = pd.cut(df_train['Credit Score'], bins=[0, 500, 650, 750, 850], \n",
    "                                      labels=['Poor', 'Fair', 'Good', 'Excellent'])\n",
    "\n",
    "# Create derived features\n",
    "df_train['Risk_Score'] = (100 - df_train['Health Score']) + (df_train['Previous Claims'] * 10)\n",
    "df_train['Income_Per_Dependent'] = df_train['Annual Income'] / (df_train['Number of Dependents'] + 1)\n",
    "\n",
    "# Interaction features\n",
    "df_train['Age_Income'] = df_train['Age'] * df_train['Annual Income']\n",
    "df_train['Age_Health'] = df_train['Age'] * df_train['Health Score']\n",
    "df_train['Credit_Income'] = df_train['Credit Score'] * df_train['Annual Income']\n",
    "df_train['Health_Claims'] = df_train['Health Score'] * df_train['Previous Claims']\n",
    "df_train['Risk_Income'] = df_train['Risk_Score'] * df_train['Annual Income']\n",
    "\n",
    "# Polynomial features\n",
    "df_train['Age_Squared'] = df_train['Age'] ** 2\n",
    "df_train['Income_Squared'] = df_train['Annual Income'] ** 2\n",
    "df_train['Health_Squared'] = df_train['Health Score'] ** 2\n",
    "df_train['Credit_Squared'] = df_train['Credit Score'] ** 2\n",
    "\n",
    "# Log transformations\n",
    "df_train['Log_Income'] = np.log1p(df_train['Annual Income'])\n",
    "df_train['Log_Income_Per_Dep'] = np.log1p(df_train['Income_Per_Dependent'])\n",
    "\n",
    "print(f\"Features after engineering: {df_train.shape[1]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335a0dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051855, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554b5d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: ENCODING CATEGORICAL VARIABLES\n",
      "============================================================\n",
      "Encoded 14 categorical columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 2: ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "categorical_cols = ['Gender', 'Marital Status', 'Education Level', 'Occupation', \n",
    "                    'Location', 'Policy Type', 'Smoking Status', 'Exercise Frequency', \n",
    "                    'Property Type', 'Customer Feedback', 'Age_Group', 'Income_Group',\n",
    "                    'Vehicle_Category', 'Credit_Category']\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"Encoded {len(categorical_cols)} categorical columns\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "444cb2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Policy_Month</th>\n",
       "      <th>Policy_Day</th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>Income_Group</th>\n",
       "      <th>Vehicle_Category</th>\n",
       "      <th>Credit_Category</th>\n",
       "      <th>Risk_Score</th>\n",
       "      <th>Income_Per_Dependent</th>\n",
       "      <th>Risk_Income</th>\n",
       "      <th>Log_Income_Per_Dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10049.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>97.401239</td>\n",
       "      <td>5024.5</td>\n",
       "      <td>9.787851e+05</td>\n",
       "      <td>8.522280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31678.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15.569731</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>94.430269</td>\n",
       "      <td>7919.5</td>\n",
       "      <td>2.991362e+06</td>\n",
       "      <td>8.977210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25602.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.177549</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.822451</td>\n",
       "      <td>6400.5</td>\n",
       "      <td>1.608380e+06</td>\n",
       "      <td>8.764288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>141855.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.938144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>99.061856</td>\n",
       "      <td>47285.0</td>\n",
       "      <td>1.405242e+07</td>\n",
       "      <td>10.763970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39651.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79.623906</td>\n",
       "      <td>19825.5</td>\n",
       "      <td>3.157168e+06</td>\n",
       "      <td>9.894775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Annual Income  Marital Status  Number of Dependents  \\\n",
       "0  19.0       0        10049.0               1                   1.0   \n",
       "1  39.0       0        31678.0               0                   3.0   \n",
       "2  23.0       1        25602.0               0                   3.0   \n",
       "3  21.0       1       141855.0               1                   2.0   \n",
       "4  21.0       1        39651.0               2                   1.0   \n",
       "\n",
       "   Education Level  Occupation  Health Score  Location  Policy Type  ...  \\\n",
       "0                0           1     22.598761         2            2  ...   \n",
       "1                2           0     15.569731         0            1  ...   \n",
       "2                1           1     47.177549         1            2  ...   \n",
       "3                0           0     10.938144         0            0  ...   \n",
       "4                0           1     20.376094         0            2  ...   \n",
       "\n",
       "   Policy_Month  Policy_Day  Age_Group  Income_Group  Vehicle_Category  \\\n",
       "0            12          23          0             1                 3   \n",
       "1             6          12          2             2                 2   \n",
       "2             9          30          0             1                 2   \n",
       "3             6          12          0             3                 1   \n",
       "4            12           1          0             2                 2   \n",
       "\n",
       "   Credit_Category  Risk_Score  Income_Per_Dependent   Risk_Income  \\\n",
       "0                3   97.401239                5024.5  9.787851e+05   \n",
       "1                2   94.430269                7919.5  2.991362e+06   \n",
       "2                1   62.822451                6400.5  1.608380e+06   \n",
       "3                3   99.061856               47285.0  1.405242e+07   \n",
       "4                1   79.623906               19825.5  3.157168e+06   \n",
       "\n",
       "   Log_Income_Per_Dep  \n",
       "0            8.522280  \n",
       "1            8.977210  \n",
       "2            8.764288  \n",
       "3           10.763970  \n",
       "4            9.894775  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a516d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1051855 entries, 0 to 1051854\n",
      "Data columns (total 40 columns):\n",
      " #   Column                Non-Null Count    Dtype  \n",
      "---  ------                --------------    -----  \n",
      " 0   Age                   1051855 non-null  float64\n",
      " 1   Gender                1051855 non-null  int64  \n",
      " 2   Annual Income         1051855 non-null  float64\n",
      " 3   Marital Status        1051855 non-null  int64  \n",
      " 4   Number of Dependents  1051855 non-null  float64\n",
      " 5   Education Level       1051855 non-null  int64  \n",
      " 6   Occupation            1051855 non-null  int64  \n",
      " 7   Health Score          1051855 non-null  float64\n",
      " 8   Location              1051855 non-null  int64  \n",
      " 9   Policy Type           1051855 non-null  int64  \n",
      " 10  Previous Claims       1051855 non-null  float64\n",
      " 11  Vehicle Age           1051855 non-null  float64\n",
      " 12  Credit Score          1051855 non-null  float64\n",
      " 13  Insurance Duration    1051855 non-null  float64\n",
      " 14  Customer Feedback     1051855 non-null  int64  \n",
      " 15  Smoking Status        1051855 non-null  int64  \n",
      " 16  Exercise Frequency    1051855 non-null  int64  \n",
      " 17  Property Type         1051855 non-null  int64  \n",
      " 18  Premium Amount        1051855 non-null  float64\n",
      " 19  Age_Income            1051855 non-null  float64\n",
      " 20  Age_Health            1051855 non-null  float64\n",
      " 21  Credit_Income         1051855 non-null  float64\n",
      " 22  Health_Claims         1051855 non-null  float64\n",
      " 23  Income_Dependents     1051855 non-null  float64\n",
      " 24  Age_Squared           1051855 non-null  float64\n",
      " 25  Income_Squared        1051855 non-null  float64\n",
      " 26  Health_Squared        1051855 non-null  float64\n",
      " 27  Credit_Squared        1051855 non-null  float64\n",
      " 28  Log_Income            1051855 non-null  float64\n",
      " 29  Policy_Year           1051855 non-null  int32  \n",
      " 30  Policy_Month          1051855 non-null  int32  \n",
      " 31  Policy_Day            1051855 non-null  int32  \n",
      " 32  Age_Group             1051855 non-null  int64  \n",
      " 33  Income_Group          1051855 non-null  int64  \n",
      " 34  Vehicle_Category      1051855 non-null  int64  \n",
      " 35  Credit_Category       1051855 non-null  int64  \n",
      " 36  Risk_Score            1051855 non-null  float64\n",
      " 37  Income_Per_Dependent  1051855 non-null  float64\n",
      " 38  Risk_Income           1051855 non-null  float64\n",
      " 39  Log_Income_Per_Dep    1051855 non-null  float64\n",
      "dtypes: float64(23), int32(3), int64(14)\n",
      "memory usage: 309.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2c7972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (841484, 39)\n",
      "X_test shape: (210371, 39)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_train.drop('Premium Amount', axis=1)\n",
    "y = df_train['Premium Amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1112cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Scaling completed\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65d3ceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "Min prediction: -773.35\n",
      "Max prediction: 1658.26\n",
      "Negative predictions: 71\n",
      "\n",
      "==================================================\n",
      "LINEAR REGRESSION RESULTS\n",
      "==================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 803.52\n",
      "  R² Score: 0.0374\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 801.70\n",
      "  RMSLE: 1.1347\n",
      "  MAE: 607.72\n",
      "  R² Score: 0.0380\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n",
    "import numpy as np\n",
    "\n",
    "print(\"Training Linear Regression...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = lr_model.predict(X_train_scaled)\n",
    "y_pred_test = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Check for negative predictions\n",
    "print(f\"Min prediction: {y_pred_test.min():.2f}\")\n",
    "print(f\"Max prediction: {y_pred_test.max():.2f}\")\n",
    "print(f\"Negative predictions: {(y_pred_test < 0).sum()}\")\n",
    "print()\n",
    "\n",
    "# Clip negative predictions to 0 for RMSLE calculation\n",
    "y_pred_test_clipped = np.maximum(y_pred_test, 0)\n",
    "\n",
    "# Metrics for test set\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred_test_clipped))\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Metrics for train set\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"LINEAR REGRESSION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {rmse_train:.2f}\")\n",
    "print(f\"  R² Score: {r2_train:.4f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {rmse:.2f}\")\n",
    "print(f\"  RMSLE: {rmsle:.4f}\")\n",
    "print(f\"  MAE: {mae:.2f}\")\n",
    "print(f\"  R² Score: {r2:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "399f2dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Training Decision Tree...\n",
      "   RMSE: 797.56, RMSLE: 1.0995, MAE: 588.75, R²: 0.0479\n",
      "\n",
      "2. Training Random Forest...\n",
      "   RMSE: 783.54, RMSLE: 1.0939, MAE: 581.90, R²: 0.0811\n",
      "\n",
      "3. Training XGBoost...\n",
      "   RMSE: 783.60, RMSLE: 1.0955, MAE: 582.81, R²: 0.0809\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "Model                RMSE         RMSLE        MAE          R² Score    \n",
      "--------------------------------------------------------------------------------\n",
      "Decision Tree        797.56       1.0995       588.75       0.0479      \n",
      "Random Forest        783.54       1.0939       581.90       0.0811      \n",
      "XGBoost              783.60       1.0955       582.81       0.0809      \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n",
    "import numpy as np\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# 1. Decision Tree\n",
    "print(\"1. Training Decision Tree...\")\n",
    "dt_model = DecisionTreeRegressor(max_depth=15, min_samples_split=20, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_test, dt_pred))\n",
    "dt_rmsle = np.sqrt(mean_squared_log_error(y_test, np.maximum(dt_pred, 0)))\n",
    "dt_mae = mean_absolute_error(y_test, dt_pred)\n",
    "dt_r2 = r2_score(y_test, dt_pred)\n",
    "\n",
    "results.append(['Decision Tree', dt_rmse, dt_rmsle, dt_mae, dt_r2])\n",
    "print(f\"   RMSE: {dt_rmse:.2f}, RMSLE: {dt_rmsle:.4f}, MAE: {dt_mae:.2f}, R²: {dt_r2:.4f}\")\n",
    "\n",
    "# 2. Random Forest\n",
    "print(\"\\n2. Training Random Forest...\")\n",
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_split=10, \n",
    "                                  min_samples_leaf=4, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "rf_rmsle = np.sqrt(mean_squared_log_error(y_test, np.maximum(rf_pred, 0)))\n",
    "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
    "rf_r2 = r2_score(y_test, rf_pred)\n",
    "\n",
    "results.append(['Random Forest', rf_rmse, rf_rmsle, rf_mae, rf_r2])\n",
    "print(f\"   RMSE: {rf_rmse:.2f}, RMSLE: {rf_rmsle:.4f}, MAE: {rf_mae:.2f}, R²: {rf_r2:.4f}\")\n",
    "\n",
    "# 3. XGBoost\n",
    "print(\"\\n3. Training XGBoost...\")\n",
    "xgb_model = XGBRegressor(n_estimators=200, max_depth=10, learning_rate=0.05, \n",
    "                         subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
    "xgb_rmsle = np.sqrt(mean_squared_log_error(y_test, np.maximum(xgb_pred, 0)))\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
    "xgb_r2 = r2_score(y_test, xgb_pred)\n",
    "\n",
    "results.append(['XGBoost', xgb_rmse, xgb_rmsle, xgb_mae, xgb_r2])\n",
    "print(f\"   RMSE: {xgb_rmse:.2f}, RMSLE: {xgb_rmsle:.4f}, MAE: {xgb_mae:.2f}, R²: {xgb_r2:.4f}\")\n",
    "\n",
    "# Summary Table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<20} {'RMSE':<12} {'RMSLE':<12} {'MAE':<12} {'R² Score':<12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result[0]:<20} {result[1]:<12.2f} {result[2]:<12.4f} {result[3]:<12.2f} {result[4]:<12.4f}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07dce5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
